#!/usr/bin/env python3
"""
Full DeepLabV3+ Training Test Script

This script demonstrates end-to-end training of the DeepLabV3+ model with the Ultralytics framework.
It runs a short training session to verify that the complete pipeline works correctly.
"""

import sys
import os
import torch
from pathlib import Path

# Set project root and apply monkey patches
project_root = '/workspaces/off-road-terrrain-seg-benchmark'
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# CRITICAL: Apply monkey patches BEFORE any Ultralytics imports
from src.patches import apply_patches
apply_patches()

# Now safe to import everything
from ultralytics.utils import DEFAULT_CFG_DICT
from src.models.deeplabv3plus.train import DeepLabV3PlusSemanticSegmentationTrainer


def run_deeplabv3plus_training():
    """Run a test training session with DeepLabV3+ model."""
    
    print("="*60)
    print("ğŸš€ DEEPLABV3+ TRAINING TEST")
    print("="*60)
    
    # Auto-detect best available device
    if torch.cuda.is_available():
        device = 'cuda'
        batch_size = 8  # Larger batch for GPU
        image_size = 320  # Larger image size for GPU
        print("ğŸš€ GPU detected - using CUDA acceleration")
    else:
        device = 'cpu'
        batch_size = 4  # Smaller batch for CPU
        image_size = 160  # Smaller image size for CPU
        print("ğŸ’» Using CPU (GPU not available)")
    
    # Training configuration
    train_config = {
        'model': '/workspaces/off-road-terrrain-seg-benchmark/src/cfg/models/deeplabv3plus_resnet50.yaml',
        'data': 'coco8-seg.yaml',  # Use standard COCO8 segmentation dataset
        'epochs': 3,  # Short test run
        'batch': batch_size,   # Auto-adjust batch size based on device
        'imgsz': image_size, # Auto-adjust image size based on device
        'device': device,  # Auto-select device
        'workers': 4 if device == 'cuda' else 1,  # More workers for GPU
        'project': f'{project_root}/runs/test_training',
        'name': f'deeplabv3plus_coco8_{device}_test',
        'exist_ok': True,
        'verbose': True,
        'save': True,
        'plots': False,  # Disable plots for cleaner output
        'val': True,     # Enable validation
        'lr0': 0.001,    # Learning rate
        'optimizer': 'Adam',
    }
    
    print("ğŸ“‹ Training Configuration:")
    for key, value in train_config.items():
        print(f"   {key}: {value}")
    
    # Detailed device information
    print(f"\nğŸ”§ Device Information:")
    print(f"   Device: {device}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name()}")
        print(f"   CUDA Version: {torch.version.cuda}")
        print(f"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print(f"   CPU: {torch.get_num_threads()} threads")
    print(f"   PyTorch: {torch.__version__}")
    
    try:
        print("\nğŸ“¦ Creating trainer...")
        trainer = DeepLabV3PlusSemanticSegmentationTrainer(overrides=train_config)
        
        print("ğŸ—ï¸  Setting up model...")
        model = trainer.get_model(cfg=train_config['model'])
        print(f"âœ… Model created: {type(model).__name__}")
        
        print("\nğŸš€ Starting training...")
        print("   Note: This is a test run with minimal epochs")
        print("   For production, use 50-100 epochs with larger batch sizes")
        
        # Start training
        results = trainer.train()
        
        print("\nâœ… TRAINING COMPLETED SUCCESSFULLY!")
        print(f"ğŸ“Š Results saved to: {trainer.save_dir}")
        
        if results:
            print("ğŸ“ˆ Training Results:")
            if hasattr(results, 'maps50'):
                print(f"   mAP@0.5: {results.maps50:.4f}")
            if hasattr(results, 'fitness'):
                print(f"   Fitness: {results.fitness:.4f}")
        
        print("\nğŸ‰ DeepLabV3+ training pipeline is fully functional!")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ TRAINING FAILED: {e}")
        import traceback
        print("\nğŸ“‹ Full error traceback:")
        traceback.print_exc()
        return False


def main():
    """Main function to run the training test."""
    
    # Check if we can access COCO8 dataset (it should be automatically downloaded)
    print("ğŸ“Š Using COCO8 segmentation dataset for testing...")
    print("   This dataset will be automatically downloaded if not present")
    
    # Run training test
    success = run_deeplabv3plus_training()
    
    if success:
        print("\n" + "="*60)
        print("ğŸŠ SUCCESS! DeepLabV3+ training pipeline works perfectly!")
        print("="*60)
        print("\nğŸ“‹ NEXT STEPS:")
        print("1. ğŸ¯ Increase epochs (50-100) for real training")
        print("2. ğŸ“Š Use larger batch sizes (4-16) for better performance")
        print("3. ğŸ–¼ï¸  Use full resolution images (640x640)")
        print("4. ğŸ”§ Fine-tune hyperparameters for your dataset")
        print("5. ğŸš€ Deploy to GPU for faster training")
        
    else:
        print("\n" + "="*60)
        print("âš ï¸  Training test failed - check errors above")
        print("="*60)
    
    return success


if __name__ == "__main__":
    main()
